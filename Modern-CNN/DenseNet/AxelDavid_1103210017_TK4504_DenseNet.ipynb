{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPWfS8DTm/ra1mtsWTKy7H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szyxxx/MachineLearning-TelkomUniversity/blob/main/Modern-CNN/DenseNet/AxelDavid_1103210017_TK4504_DenseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Axel David<br>\n",
        "NIM: 1103210017<br>\n",
        "Judul Tugas: Pembuatan Model CNN Modern - DenseNet<br>\n",
        "Lecture: 12<br>\n",
        "Model: DenseNet<br>\n",
        "Dataset: CIFAR-10"
      ],
      "metadata": {
        "id": "g_OhXKJVYsXS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TlUwJUDYIsO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "import tensorflow as tf\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengunduh dataset CIFAR-10\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalisasi dataset\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Konversi label ke tensor\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long).squeeze()\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.long).squeeze()\n",
        "\n",
        "# Membuat transformasi\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),  # Mengonversi gambar menjadi PIL Image\n",
        "    transforms.Resize(224),  # Mengubah ukuran gambar menjadi 224x224\n",
        "    transforms.ToTensor(),  # Mengonversi gambar menjadi tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalisasi gambar\n",
        "])\n",
        "\n",
        "# Membuat dataset CIFAR-10\n",
        "class CIFAR10Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "trainset = CIFAR10Dataset(train_images, train_labels, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = CIFAR10Dataset(test_images, test_labels, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "S4cDjAyNY0ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan blok Dense\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n",
        "        self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(self.bn1(x))\n",
        "        out = self.conv2(self.bn2(out))\n",
        "        out = torch.cat([out, x], 1)\n",
        "        return out\n",
        "\n",
        "# Mendefinisikan blok Transition\n",
        "class Transition(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Transition, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.pool = nn.AvgPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(self.bn(x))\n",
        "        out = self.pool(out)\n",
        "        return out\n",
        "\n",
        "# Mendefinisikan arsitektur DenseNet\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_blocks, growth_rate=12, reduction=0.5, num_classes=10):\n",
        "        super(DenseNet, self).__init__()\n",
        "        num_planes = 2 * growth_rate\n",
        "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "        self.dense1 = self._make_dense_layers(Bottleneck, num_planes, num_blocks[0], growth_rate)\n",
        "        num_planes += num_blocks[0] * growth_rate\n",
        "        out_planes = int(math.floor(num_planes * reduction))\n",
        "        self.trans1 = Transition(num_planes, out_planes)\n",
        "        num_planes = out_planes\n",
        "\n",
        "        self.dense2 = self._make_dense_layers(Bottleneck, num_planes, num_blocks[1], growth_rate)\n",
        "        num_planes += num_blocks[1] * growth_rate\n",
        "        out_planes = int(math.floor(num_planes * reduction))\n",
        "        self.trans2 = Transition(num_planes, out_planes)\n",
        "        num_planes = out_planes\n",
        "\n",
        "        self.dense3 = self._make_dense_layers(Bottleneck, num_planes, num_blocks[2], growth_rate)\n",
        "        num_planes += num_blocks[2] * growth_rate\n",
        "        out_planes = int(math.floor(num_planes * reduction))\n",
        "        self.trans3 = Transition(num_planes, out_planes)\n",
        "        num_planes = out_planes\n",
        "\n",
        "        self.dense4 = self._make_dense_layers(Bottleneck, num_planes, num_blocks[3], growth_rate)\n",
        "        num_planes += num_blocks[3] * growth_rate\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(num_planes)\n",
        "        self.linear = nn.Linear(num_planes, num_classes)\n",
        "\n",
        "    def _make_dense_layers(self, block, in_channels, nblock, growth_rate):\n",
        "        layers = []\n",
        "        for i in range(nblock):\n",
        "            layers.append(block(in_channels, growth_rate))\n",
        "            in_channels += growth_rate\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.trans1(self.dense1(out))\n",
        "        out = self.trans2(self.dense2(out))\n",
        "        out = self.trans3(self.dense3(out))\n",
        "        out = self.dense4(out)\n",
        "        out = torch.squeeze(out)\n",
        "        out = self.bn(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def densenet121():\n",
        "    return DenseNet(num_blocks=[6, 12, 24, 16], growth_rate=32)\n",
        "\n",
        "net_densenet = densenet121()"
      ],
      "metadata": {
        "id": "GAv4Z13WY1xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net_densenet.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "DQ8S7BkhZzi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net_densenet.to(device)\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net_densenet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:  # Cetak setiap 10 batch\n",
        "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 10:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "pEZFq3kaZ19h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net_densenet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "id": "Aad7L0_FZ3-b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}